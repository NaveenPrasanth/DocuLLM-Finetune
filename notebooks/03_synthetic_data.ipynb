{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Synthetic Data Generation\n",
    "\n",
    "Walk through the Claude-powered synthetic data generation pipeline for DocuMind.\n",
    "We generate three types of synthetic training data:\n",
    "\n",
    "1. **Instruction variants** - Diverse paraphrases of the receipt extraction instruction\n",
    "2. **Synthetic receipts** - Realistic receipt JSON following the CORD v2 schema\n",
    "3. **Error augmentations** - OCR-like corruptions paired with clean corrections\n",
    "\n",
    "This notebook uses small sample sizes for demonstration. Use `scripts/generate_synthetic.py` for full-scale generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# ── Setup: works on both Colab and local ──────────────────────────\nimport os, sys\n\nIN_COLAB = 'google.colab' in sys.modules or os.path.exists('/content')\n\nif IN_COLAB:\n    try:\n        os.getcwd()\n    except OSError:\n        os.chdir(\"/content\")\n\n    REPO_URL = \"https://github.com/NaveenPrasanth/DocuLLM-Finetune.git\"\n    REPO_DIR = \"/content/DocuLLM-Finetune\"\n    if not os.path.exists(REPO_DIR):\n        os.chdir(\"/content\")\n        !git clone {REPO_URL} {REPO_DIR}\n    os.chdir(REPO_DIR)\n    !pip install -q \"anthropic>=0.18\" \"datasets>=2.20.0\" \"omegaconf>=2.3\" \\\n        \"pydantic>=2.5\" \"rapidfuzz>=3.5\" \"python-dotenv>=1.0\" rich\n    !pip install -q -e .\nelse:\n    sys.path.insert(0, '..')\n\nimport json\nfrom pathlib import Path\n\nfrom src.config import get_env_var, load_base_config\nfrom src.data.cord_loader import get_cord_schema\nfrom src.data.synthetic_generator import SyntheticGenerator\n\nprint('Imports loaded successfully.')\nprint(f'CORD schema keys: {list(get_cord_schema().keys())}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator with API key\n",
    "# Set your key in the environment or paste it below (do NOT commit secrets)\n",
    "api_key = get_env_var('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        'ANTHROPIC_API_KEY not found. '\n",
    "        'Set it in your .env file or export it in your shell.'\n",
    "    )\n",
    "\n",
    "generator = SyntheticGenerator(api_key=api_key)\n",
    "print(f'Generator ready (model={generator.model})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 instruction variants (demo)\n",
    "instruction_variants = generator.generate_instruction_variants(num_variants=5)\n",
    "\n",
    "print(f'Generated {len(instruction_variants)} instruction variants:\\n')\n",
    "for i, variant in enumerate(instruction_variants, 1):\n",
    "    print(f'  [{i}] {variant}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3 synthetic receipts (demo)\n",
    "synthetic_receipts = generator.generate_synthetic_receipts(num_receipts=3)\n",
    "\n",
    "print(f'Generated {len(synthetic_receipts)} synthetic receipts:\\n')\n",
    "for i, receipt in enumerate(synthetic_receipts, 1):\n",
    "    parsed = json.loads(receipt['ground_truth_json'])\n",
    "    print(f'--- Receipt {i} ---')\n",
    "    print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 error augmentation pairs (demo)\n",
    "error_pairs = generator.generate_error_augmentations(\n",
    "    receipts=synthetic_receipts,\n",
    "    num_pairs=2,\n",
    ")\n",
    "\n",
    "print(f'Generated {len(error_pairs)} error augmentation pairs:\\n')\n",
    "for i, pair in enumerate(error_pairs, 1):\n",
    "    print(f'=== Pair {i} ===')\n",
    "    print('\\nCORRUPTED (simulated OCR errors):')\n",
    "    print(json.dumps(pair['corrupted'], indent=2, ensure_ascii=False))\n",
    "    print('\\nCORRECTED (clean ground truth):')\n",
    "    print(json.dumps(pair['corrected'], indent=2, ensure_ascii=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples and statistics\n",
    "usage = generator.get_usage_summary()\n",
    "\n",
    "print('=' * 50)\n",
    "print('  Generation Statistics')\n",
    "print('=' * 50)\n",
    "print(f'  Instruction variants : {len(instruction_variants)}')\n",
    "print(f'  Synthetic receipts   : {len(synthetic_receipts)}')\n",
    "print(f'  Error augment pairs  : {len(error_pairs)}')\n",
    "print('-' * 50)\n",
    "print(f'  Input tokens         : {usage[\"input_tokens\"]:,}')\n",
    "print(f'  Output tokens        : {usage[\"output_tokens\"]:,}')\n",
    "print(f'  Estimated cost (USD) : ${usage[\"estimated_cost_usd\"]:.4f}')\n",
    "print('=' * 50)\n",
    "\n",
    "# Analyze receipt complexity\n",
    "print('\\nReceipt complexity analysis:')\n",
    "for i, receipt in enumerate(synthetic_receipts, 1):\n",
    "    parsed = json.loads(receipt['ground_truth_json'])\n",
    "    num_menu_items = len(parsed.get('menu', []))\n",
    "    has_total = 'total' in parsed\n",
    "    has_subtotal = 'sub_total' in parsed\n",
    "    total_fields = sum(\n",
    "        len(v) if isinstance(v, (list, dict)) else 1\n",
    "        for v in parsed.values()\n",
    "    )\n",
    "    print(\n",
    "        f'  Receipt {i}: {num_menu_items} menu items, '\n",
    "        f'total={has_total}, subtotal={has_subtotal}, '\n",
    "        f'~{total_fields} top-level elements'\n",
    "    )\n",
    "\n",
    "# Analyze error types\n",
    "print('\\nError augmentation examples:')\n",
    "for i, pair in enumerate(error_pairs, 1):\n",
    "    corrupted_str = json.dumps(pair['corrupted'])\n",
    "    corrected_str = json.dumps(pair['corrected'])\n",
    "    # Simple diff: count character-level differences\n",
    "    min_len = min(len(corrupted_str), len(corrected_str))\n",
    "    diffs = sum(1 for a, b in zip(corrupted_str[:min_len], corrected_str[:min_len]) if a != b)\n",
    "    len_diff = abs(len(corrupted_str) - len(corrected_str))\n",
    "    print(\n",
    "        f'  Pair {i}: {diffs} char substitutions, '\n",
    "        f'{len_diff} length difference'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Instruction Variants\n",
    "The generated instruction variants cover multiple communication styles (formal, casual, concise, detailed, etc.), which helps the model generalise across different user phrasings at inference time. During training, we randomly sample from these variants instead of using a single fixed instruction.\n",
    "\n",
    "### Synthetic Receipts\n",
    "Each synthetic receipt follows the CORD v2 schema with varying complexity:\n",
    "- **Simple receipts** (2-3 items) simulate quick purchases\n",
    "- **Complex receipts** (6-8 items) simulate restaurant or grocery bills\n",
    "- Prices, quantities, and totals are mathematically plausible\n",
    "- Sparse fields (void_menu, discount, e-money) appear only occasionally, matching real-world distributions\n",
    "\n",
    "### Error Augmentations\n",
    "OCR error simulation covers the most common failure modes:\n",
    "- Character confusion (l/1, O/0, S/5) which are frequent in receipt fonts\n",
    "- Word merging and splitting from poor line segmentation\n",
    "- Number corruption which directly impacts financial accuracy\n",
    "- Field truncation simulating partial scans\n",
    "\n",
    "Training on these pairs teaches the model to recover clean data from noisy OCR input.\n",
    "\n",
    "### Cost Considerations\n",
    "For production-scale generation (20 instructions + 100 receipts + 50 error pairs), expect approximately:\n",
    "- ~50k-100k input tokens and ~100k-200k output tokens\n",
    "- Estimated cost: $1-3 USD with Claude 3.5 Sonnet\n",
    "\n",
    "### Next Steps\n",
    "Run the full generation pipeline with:\n",
    "```bash\n",
    "python scripts/generate_synthetic.py --num-receipts 100 --num-error-pairs 50 --output-dir data/synthetic\n",
    "```\n",
    "Then integrate synthetic data into training via `dataset_builder.add_synthetic_data()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}